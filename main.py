import sys
import os

# Streamlit Cloud(Linux)ì—ì„œë§Œ pysqlite3 ì‚¬ìš©
if os.environ.get("STREAMLIT_CLOUD") == "true":
    try:
        __import__("pysqlite3")
        sys.modules["sqlite3"] = sys.modules.pop("pysqlite3")
    except ModuleNotFoundError:
        pass

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_classic.retrievers.multi_query import MultiQueryRetriever
from langchain_classic.chains import RetrievalQA

import streamlit as st
import tempfile
import os
import hashlib

# =================================================
# ê¸°ë³¸ ì„¤ì •
# =================================================
load_dotenv()

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PERSIST_DIR = os.path.join(BASE_DIR, "chroma_langchain_db")

# =================================================
# Streamlit UI Title
# =================================================
st.title("ğŸ“„ ChatPDF")
st.write("---")

# =================================================
# OPENAI_API_KEY AI í‚¤ ì…ë ¥ ë°›ê³ ,
# í™˜ê²½ ë³€ìˆ˜ ë“±ë¡, í•˜ìœ„ OpenAI ê´€ë ¨ APIëŠ” ëƒ…ë‘¬ë„ë¨. 
# =================================================
openai_key= st.text_input("OPENAI_API_KEY", type="password")

if openai_key:
    os.environ["OPENAI_API_KEY"] = openai_key

# =================================================
# Streamlit UI File Upload
# =================================================

uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"])
st.write("---")

# =================================================
# Utils
# =================================================
def file_hash(uploaded_file) -> str:
    return hashlib.sha256(uploaded_file.getvalue()).hexdigest()

@st.cache_resource
def load_vectorstore(collection_name: str):
    embeddings = OpenAIEmbeddings()
    return Chroma(
        collection_name=collection_name,
        embedding_function=embeddings,
        persist_directory=PERSIST_DIR,
    )

# =================================================
# PDF ì²˜ë¦¬
# =================================================
if uploaded_file is not None:
    file_id = file_hash(uploaded_file)
    collection_name = f"pdf_{file_id[:12]}"

    vector_store = load_vectorstore(collection_name)

    # âœ… ì„ë² ë”© ìŠ¤í”¼ë„ˆ (ìµœì´ˆ 1íšŒë§Œ)
    if vector_store._collection.count() == 0:
        with st.spinner("ğŸ“Œ ì²˜ìŒ ì—…ë¡œë“œëœ PDFì…ë‹ˆë‹¤. ì„ë² ë”© ì¤‘ì…ë‹ˆë‹¤..."):
            with tempfile.TemporaryDirectory() as temp_dir:
                temp_path = os.path.join(temp_dir, uploaded_file.name)
                with open(temp_path, "wb") as f:
                    f.write(uploaded_file.getvalue())

                loader = PyPDFLoader(temp_path)
                documents = loader.load()

                splitter = RecursiveCharacterTextSplitter(
                    chunk_size=300,
                    chunk_overlap=20
                )
                split_docs = splitter.split_documents(documents)

                vector_store.add_documents(split_docs)
                try:
                    vector_store.persist()
                except Exception:
                    pass

        st.success("âœ… ì„ë² ë”© ì™„ë£Œ!")
    else:
        st.success("âœ… ê¸°ì¡´ ë²¡í„° DB ì¬ì‚¬ìš©")

    st.write("---")

    # Retriever / QA
    llm = ChatOpenAI(temperature=0, max_completion_tokens=2048)
    base_retriever = vector_store.as_retriever(search_kwargs={"k": 4})

    mqr = MultiQueryRetriever.from_llm(
        retriever=base_retriever,
        llm=llm,
        include_original=True
    )

    qa = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=mqr,
        return_source_documents=True
    )

    # ë¬¸ì„œ ìš”ì•½
    if st.button("ğŸ“Œ ë¬¸ì„œ ìš”ì•½"):
        with st.spinner("ğŸ§  ë¬¸ì„œ ìš”ì•½ ìƒì„± ì¤‘..."):
            result = qa.invoke({"query": "ì´ ë¬¸ì„œ í•µì‹¬ ìš”ì•½í•´ì¤˜"})
        st.subheader("ğŸ“Œ ìš”ì•½")
        st.write(result["result"])

    st.write("---")

    # PDFì—ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”
    st.subheader("ğŸ¤– PDFì—ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”")
    user_question = st.text_input(
        label="",
        placeholder="PDF ë‚´ìš©ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”",
    )

    if user_question and st.button("ì§ˆë¬¸í•˜ê¸°"):
        with st.spinner("ğŸ” ë¬¸ì„œë¥¼ ì°¾ê³  ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
            result = qa.invoke({"query": user_question})

        st.subheader("ğŸ’¬ ë‹µë³€")
        st.write(result["result"])

        st.subheader("ğŸ“ ê·¼ê±° ë¬¸ì„œ (í˜ì´ì§€)")
        for i, doc in enumerate(result["source_documents"], 1):
            st.markdown(f"**[{i}] page {doc.metadata.get('page')}**")
            st.text(doc.page_content[:300])
else:
    st.info("PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ ì§ˆë¬¸ ì…ë ¥ì°½ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")
